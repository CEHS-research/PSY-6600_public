AFO_2, #None need to be reverse coded
AFO_3, ##Family Obligation
AFO_4,
AFO_5,
AFO_6,
AFO_7,
AFO_8,
AFO_9,
AFO_10,
AFO_11)) %>%
dplyr::mutate(resp = furniture:: rowmeans(AF_12, # Respect for family
AF_13,
AF_14,
AF_15,
AF_16,
AF_17,
AF_18)) %>%
dplyr::mutate(sup = furniture:: rowmeans(AF_19, # Future support
AF_20,
AF_21,
AF_22,
AF_23,
AF_24)) %>%
dplyr::mutate_at(vars(SEE_1, SEE_2, SEE_3, SEE_4,
SEE_5, SEE_11, SEE_15), # Reverse Code  (new = 6 - old)
function(x) 6 - x) %>%
dplyr::mutate(ei = furniture::rowmeans(SEE_1, # ethnic identity
SEE_2,  ##Ethnic Experience
SEE_3,
SEE_4,
SEE_5,
SEE_6,
SEE_7,
SEE_8,
SEE_9,
SEE_10,
SEE_11,
SEE_12)) %>%
dplyr::mutate(mc = furniture::rowmeans(SEE_13, # mainstream comfort
SEE_14,
SEE_15,
SEE_16,
SEE_17,
SEE_18)) %>%
dplyr::mutate(sex2 = ordered(sex2)) %>%
dplyr::mutate(sex_female = (sex2 == "Female") %>% as.numeric) %>%
dplyr::mutate(sex_other = (sex2 == "Other") %>% as.numeric) %>%
dplyr::mutate(generation_statusNA = generation_status %>%
forcats::fct_recode(NULL = "Unsure",
NULL = "Prefer not to answer") %>%
ordered()) %>%
dplyr::mutate(billsNA = bills %>%
forcats::fct_recode(NULL = "Prefer not to answer") %>%
forcats::fct_drop() %>%
ordered()) %>%
dplyr::mutate(moneyNA = money %>%
forcats::fct_recode(NULL = "Prefer not to answer") %>%
forcats::fct_drop() %>%
ordered())
df_scored %>%
dplyr::filter(.imp == 0) %>% #sex
dplyr::select(sex_female, sex_other) %>%
table() %>%
addmargins()
mids_scored <- df_scored %>%
# dplyr::filter(complete.cases(sex2, generation_statusNA, moneyNA)) %>%
dplyr::filter(.imp > 0) %>%  # removes the original dataset we don't need
dplyr::group_by(.imp) %>%
tidyr::nest() %>%
dplyr::pull(data) %>%
as.list()
model1b <-
'
#regressions
asi_phys   ~ assist + resp + sup + ei + mc + sex_female + sex_other
asi_cog    ~ assist + resp + sup + ei + mc
asi_soc    ~ assist + resp + sup + ei + mc
cesd_som   ~ assist + resp + sup + ei + mc
cesd_pos   ~ assist + resp + sup + ei + mc
cesd_dep   ~ assist + resp + sup + ei + mc
cesd_int   ~ assist + resp + sup + ei + mc
#correlated residuals
asi_phys   ~~ asi_cog + asi_soc + cesd_som + cesd_pos + cesd_dep + cesd_int
asi_cog    ~~ asi_soc + cesd_som + cesd_pos + cesd_dep + cesd_int
asi_soc    ~~ cesd_som + cesd_pos + cesd_dep + cesd_int
cesd_som   ~~ cesd_pos + cesd_dep + cesd_int
cesd_pos   ~~ cesd_dep + cesd_int
cesd_dep   ~~  cesd_int
#covariances between predictors
assist ~~ resp + sup + ei + mc
resp   ~~ sup + ei + mc
sup    ~~ ei + mc
ei     ~~ mc
'
# analysis based on all imputed datasets
fit1 <- mids_scored %>%         #use mids format
lapply(FUN = function(df){    # lapply runs the function list-wise over all the 50 MI dataframes
res <- lavaan::sem(model1b,
data = df)
return(res)
}
)
semPaths(model1b,
as.expression = c("nodes", "edges"),
sizeMan = 5,  # adjust size of boxes
sizeInt = 1,
sizeLat = 4)
library(semPlot)
install.packages("semPlot")
library(semPlot)
semPaths(model1b,
as.expression = c("nodes", "edges"),
sizeMan = 5,  # adjust size of boxes
sizeInt = 1,
sizeLat = 4)
semPaths(model1b ,
"eq",
layout = "tree")
semPaths(model1b)
# analysis based on all imputed datasets
fit1 <- mids_scored %>%         #use mids format
lapply(FUN = function(df){    # lapply runs the function list-wise over all the 50 MI dataframes
res <- lavaan::sem(model1b,
data = df,
fixed.x = TRUE)
return(res)
}
)
model1b <-
'
#regressions
asi_phys   ~ assist + resp + sup + ei + mc + sex_female + sex_other
asi_cog    ~ assist + resp + sup + ei + mc
asi_soc    ~ assist + resp + sup + ei + mc
cesd_som   ~ assist + resp + sup + ei + mc
cesd_pos   ~ assist + resp + sup + ei + mc
cesd_dep   ~ assist + resp + sup + ei + mc
cesd_int   ~ assist + resp + sup + ei + mc
#correlated residuals
asi_phys   ~~ asi_cog + asi_soc + cesd_som + cesd_pos + cesd_dep + cesd_int
asi_cog    ~~ asi_soc + cesd_som + cesd_pos + cesd_dep + cesd_int
asi_soc    ~~ cesd_som + cesd_pos + cesd_dep + cesd_int
cesd_som   ~~ cesd_pos + cesd_dep + cesd_int
cesd_pos   ~~ cesd_dep + cesd_int
cesd_dep   ~~  cesd_int
#covariances between predictors
assist ~~ resp + sup + ei + mc
resp   ~~ sup + ei + mc
sup    ~~ ei + mc
ei     ~~ mc
#variance
sex_female ~~ sex_female
sex_other ~~ sex_other
'
# analysis based on all imputed datasets
fit1 <- mids_scored %>%         #use mids format
lapply(FUN = function(df){    # lapply runs the function list-wise over all the 50 MI dataframes
res <- lavaan::sem(model1b,
data = df,
fixed.x = TRUE)
return(res)
}
)
# analysis based on all imputed datasets
fit1 <- mids_scored %>%         #use mids format
lapply(FUN = function(df){    # lapply runs the function list-wise over all the 50 MI dataframes
res <- lavaan::sem(model1b,
data = df,
fixed.x = FALSE)
return(res)
}
)
varTable(fit1[1])
lavaan::varTable(fit1[1])
fit1[1]
varTable(fit1[1])
?varTable
lavaan::varTable(fit1[1])
?lavaan::varTable
lavaan::varTable(fit1[1])
class(fit1[1])
class(fit1[[1]])
lavaan::varTable(fit1[[1]])
lavaan::varTable(fit1[[2]])
lavaan::varTable(fit1[[29]])
# analysis based on all imputed datasets
fit1 <- mids_scored %>%         #use mids format
lapply(FUN = function(df){    # lapply runs the function list-wise over all the 50 MI dataframes
res <- lavaan::sem(model1b,
data = df %>%
dplyr::filter(sex2 %in% C("Male", "Female")),
fixed.x = FALSE)
return(res)
}
)
# analysis based on all imputed datasets
fit1 <- mids_scored %>%         #use mids format
lapply(FUN = function(df){    # lapply runs the function list-wise over all the 50 MI dataframes
res <- lavaan::sem(model1b,
data = df %>%
dplyr::filter(sex2 %in% c("Male", "Female")),
fixed.x = FALSE)
return(res)
}
)
# analysis based on all imputed datasets
fit1 <- mids_scored %>%         #use mids format
lapply(FUN = function(df){    # lapply runs the function list-wise over all the 50 MI dataframes
res <- lavaan::sem(model1b,
data = df %>%
dplyr::filter(sex_other == 0),
fixed.x = FALSE)
return(res)
}
)
model1b <-
'
#regressions
asi_phys   ~ assist + resp + sup + ei + mc + sex_female
asi_cog    ~ assist + resp + sup + ei + mc
asi_soc    ~ assist + resp + sup + ei + mc
cesd_som   ~ assist + resp + sup + ei + mc
cesd_pos   ~ assist + resp + sup + ei + mc
cesd_dep   ~ assist + resp + sup + ei + mc
cesd_int   ~ assist + resp + sup + ei + mc
#correlated residuals
asi_phys   ~~ asi_cog + asi_soc + cesd_som + cesd_pos + cesd_dep + cesd_int
asi_cog    ~~ asi_soc + cesd_som + cesd_pos + cesd_dep + cesd_int
asi_soc    ~~ cesd_som + cesd_pos + cesd_dep + cesd_int
cesd_som   ~~ cesd_pos + cesd_dep + cesd_int
cesd_pos   ~~ cesd_dep + cesd_int
cesd_dep   ~~  cesd_int
#covariances between predictors
assist ~~ resp + sup + ei + mc
resp   ~~ sup + ei + mc
sup    ~~ ei + mc
ei     ~~ mc
'
# analysis based on all imputed datasets
fit1 <- mids_scored %>%         #use mids format
lapply(FUN = function(df){    # lapply runs the function list-wise over all the 50 MI dataframes
res <- lavaan::sem(model1b,
data = df %>%
dplyr::filter(sex_other == 0),
fixed.x = FALSE)
return(res)
}
)
lavaan::varTable(fit1[[29]])
model1b <-
'
#regressions
asi_phys   ~ assist + resp + sup + ei + mc + sex_female
asi_cog    ~ assist + resp + sup + ei + mc + sex_female
asi_soc    ~ assist + resp + sup + ei + mc + sex_female
cesd_som   ~ assist + resp + sup + ei + mc + sex_female
cesd_pos   ~ assist + resp + sup + ei + mc + sex_female
cesd_dep   ~ assist + resp + sup + ei + mc + sex_female
cesd_int   ~ assist + resp + sup + ei + mc + sex_female
#correlated residuals
asi_phys   ~~ asi_cog + asi_soc + cesd_som + cesd_pos + cesd_dep + cesd_int
asi_cog    ~~ asi_soc + cesd_som + cesd_pos + cesd_dep + cesd_int
asi_soc    ~~ cesd_som + cesd_pos + cesd_dep + cesd_int
cesd_som   ~~ cesd_pos + cesd_dep + cesd_int
cesd_pos   ~~ cesd_dep + cesd_int
cesd_dep   ~~  cesd_int
#covariances between predictors
assist ~~ resp + sup + ei + mc
resp   ~~ sup + ei + mc
sup    ~~ ei + mc
ei     ~~ mc
'
# analysis based on all imputed datasets
fit1 <- mids_scored %>%         #use mids format
lapply(FUN = function(df){    # lapply runs the function list-wise over all the 50 MI dataframes
res <- lavaan::sem(model1b,
data = df %>%
dplyr::filter(sex_other == 0), # remove the 6 with "other" sex
fixed.x = FALSE)
return(res)
}
)
# Beta estimates (point estimates)
qhat <- lapply( fit1 , FUN = function(ll){
h1 <- lavaan::parameterEstimates(ll)
parnames <- paste0( h1$lhs , h1$op , h1$rhs )
v1 <- h1$est
names(v1) <- parnames
return(v1)
} )
# Standard error of the beta estimates
se <- lapply( fit1 , FUN = function(ll){
h1 <- lavaan::parameterEstimates(ll)
parnames <- paste0( h1$lhs , h1$op , h1$rhs )
v1 <- h1$se
names(v1) <- parnames
return(v1)
} )
# Square the SE to get Variances
se2 <- lapply( se , FUN = function(ss){ ss^2 } )
# use mitml for mediation, input beta estimates and their variances
results1 <- mitml::testEstimates(qhat=qhat,  # point estimates
uhat=se2)   # variance around the point estimates
#confidence intervals
confint(results1, level = 0.95)
#view results (pooled for all 50 replications)
results1
remotes::install_github("tysonstanley/furniture")
Enter one or more numbers, or an empty line to skip updates:
remotes::install_github("tysonstanley/furniture")
# set global chunk options...
#  this changes the defaults so you don't have to repeat yourself
knitr::opts_chunk$set(comment     = NA,
echo        = TRUE,
warning     = FALSE,
message     = FALSE,
fig.align   = "center", # center all figures
fig.width   = 4,        # set default figure width to 4 inches
fig.height  = 3)        # set default figure height to 3 inches
library(tidyverse)    # Loads several very helpful 'tidy' packages
library(readxl)       # Read in Excel datasets
library(furniture)    # Nice tables (by our own Tyson Barrett)
library(psych)        # Lots of nice tid-bits
library(car)          # Companion to "Applied Regression"
data_clean <- read_excel("Ihno_dataset.xls") %>%
dplyr::rename_all(tolower) %>%
dplyr::mutate(genderF = factor(gender,
levels = c(1, 2),
labels = c("Female",
"Male"))) %>%
dplyr::mutate(majorF = factor(major,
levels = c(1, 2, 3, 4,5),
labels = c("Psychology",
"Premed",
"Biology",
"Sociology",
"Economics"))) %>%
dplyr::mutate(reasonF = factor(reason,
levels = c(1, 2, 3),
labels = c("Program requirement",
"Personal interest",
"Advisor recommendation"))) %>%
dplyr::mutate(exp_condF = factor(exp_cond,
levels = c(1, 2, 3, 4),
labels = c("Easy",
"Moderate",
"Difficult",
"Impossible"))) %>%
dplyr::mutate(coffeeF = factor(coffee,
levels = c(0, 1),
labels = c("Not a regular coffee drinker",
"Regularly drinks coffee")))  %>%
dplyr::mutate(hr_base_bps = hr_base / 60) %>%
dplyr::mutate(anx_plus = rowsums(anx_base, anx_pre, anx_post)) %>%
dplyr::mutate(hr_avg = rowmeans(hr_base + hr_pre + hr_post)) %>%
dplyr::mutate(statDiff = statquiz - exp_sqz)
# Find the mean and n for: mathquiz, statquiz  <-- default settings: na.rm = TRUE
data_clean %>%
furniture::table1(mathquiz, statquiz)
# Find the mean and n for: mathquiz, statquiz
data_clean %>%
furniture::table1(mathquiz, statquiz,
na.rm = FALSE)
# Find the mean and n for: mathquiz, statquiz
data_clean %>%
dplyr::select(mathquiz, statquiz) %>%
psych::describe()
library(tidyverse)    # Loads several very helpful 'tidy' packages
library(readxl)       # Read in Excel datasets
library(furniture)    # Nice tables (by our own Tyson Barrett)
schizo <- data.frame(id       = c(1:10),
yr_hos   = c( 5,  7, 12,  5, 11,  3,  7,  2,  9,  6),
ori_test = c(22, 26, 16, 20, 18, 30, 14, 24, 15, 19))
GRE <- data.frame(id          = c(1:5),
verbalGRE_1 = c(540, 510, 580, 550, 520),
verbalGRE_2 = c(570, 520, 600, 530, 520))
test_scores <-  data.frame(id      = c(1:12),
spatial = c(13, 32, 41, 26, 28, 12, 19, 33, 24, 46, 22, 17),
math    = c(19, 25, 31, 18, 37, 16, 14, 28, 20, 39, 21, 15))
child_vars  <-  data.frame(child = c(1:8),
shoe  = c(5.2, 4.7, 7.0, 5.8, 7.2, 6.9, 7.7, 8.0),
read  = c(1.7, 1.5, 2.7, 3.1, 3.9, 4.5, 5.1, 7.4),
age   = c(  5,   6,   7,   8,   9,  10,  11,  12))
memory <- data.frame(id    = c(1:9),
sound = c(8, 5, 6, 10, 3, 4, 7, 11, 9),
look  = c(4, 5, 3, 11, 2, 6, 4,  6, 7))
schizo
# Pearson's r: yr_hos & ori_test
schizo %>%
cor.test( ~ yr_hos + ori_test,
data = .)
GRE
# Pearson's r: verbalGRE_1 & verbalGRE_2 --> ONE tail
GRE %>%
cor.test(~ verbalGRE_1 + verbalGRE_2,
data = .,
alternative = "greater")
# Pearson's r: verbalGRE_1 & verbalGRE_2 --> ONE tail
GRE %>%
cor.test(~ verbalGRE_1 + verbalGRE_2,
data = .,
alternative = "greater")
# Pearson's r: verbalGRE_1 & verbalGRE_2 --> ONE tail
GRE %>%
cor.test(~ verbalGRE_1 + verbalGRE_2,
data = .)
# Pearson's r: verbalGRE_1 & verbalGRE_2 --> ONE tail
GRE %>%
cor.test(~ verbalGRE_1 + verbalGRE_2,
data = .,
alternative = "greater")
# Pearson's r: verbalGRE_1 & verbalGRE_2 --> TWO tails
GRE %>%
cor.test(~ verbalGRE_1 + verbalGRE_2,
data = .,
alternative = "two.sided")
# Pearson's r: verbalGRE_1 & verbalGRE_2 --> ONE tail
GRE %>%
cor.test(~ verbalGRE_1 + verbalGRE_2,
data = .,
alternative = "less")
# Pearson's r: verbalGRE_1 & verbalGRE_2 --> ONE tail
GRE %>%
cor.test(~ verbalGRE_1 + verbalGRE_2,
data = .,
alternative = "greater")
# Pearson's r: verbalGRE_1 & verbalGRE_2 --> TWO tails
GRE %>%
cor.test(~ verbalGRE_1 + verbalGRE_2,
data = .,
alternative = "two.sided",
method = "pearson")
schizo <- data.frame(id       = c(1:10),
yr_hos   = c( 5,  7, 12,  5, 11,  3,  7,  2,  9,  6),
ori_test = c(22, 26, 16, 20, 18, 30, 14, 24, 15, 19))
GRE <- data.frame(id          = c(1:5),
verbalGRE_1 = c(540, 510, 580, 550, 520),
verbalGRE_2 = c(570, 520, 600, 530, 520))
test_scores <-  data.frame(id      = c(1:12),
spatial = c(13, 32, 41, 26, 28, 12, 19, 33, 24, 46, 22, 17),
math    = c(19, 25, 31, 18, 37, 16, 14, 28, 20, 39, 21, 15))
child_vars  <-  data.frame(child = c(1:8),
shoe  = c(5.2, 4.7, 7.0, 5.8, 7.2, 6.9, 7.7, 8.0),
read  = c(1.7, 1.5, 2.7, 3.1, 3.9, 4.5, 5.1, 7.4),
age   = c(  5,   6,   7,   8,   9,  10,  11,  12))
memory <- data.frame(id    = c(1:9),
sound = c(8, 5, 6, 10, 3, 4, 7, 11, 9),
look  = c(4, 5, 3, 11, 2, 6, 4,  6, 7))
# set global chunk options...
#  this changes the defaults so you don't have to repeat yourself
knitr::opts_chunk$set(comment     = NA,
cache       = TRUE,
echo        = TRUE,
warning     = FALSE,
message     = FALSE,
fig.align   = "center", # center all figures
fig.width   = 6,        # set default figure width to 4 inches
fig.height  = 4)        # set default figure height to 3 inches
library(tidyverse)    # Loads several very helpful 'tidy' packages
library(readxl)       # Read in Excel datasets
library(furniture)    # Nice tables (by our own Tyson Barrett)
schizo <- data.frame(id       = c(1:10),
yr_hos   = c( 5,  7, 12,  5, 11,  3,  7,  2,  9,  6),
ori_test = c(22, 26, 16, 20, 18, 30, 14, 24, 15, 19))
GRE <- data.frame(id          = c(1:5),
verbalGRE_1 = c(540, 510, 580, 550, 520),
verbalGRE_2 = c(570, 520, 600, 530, 520))
test_scores <-  data.frame(id      = c(1:12),
spatial = c(13, 32, 41, 26, 28, 12, 19, 33, 24, 46, 22, 17),
math    = c(19, 25, 31, 18, 37, 16, 14, 28, 20, 39, 21, 15))
child_vars  <-  data.frame(child = c(1:8),
shoe  = c(5.2, 4.7, 7.0, 5.8, 7.2, 6.9, 7.7, 8.0),
read  = c(1.7, 1.5, 2.7, 3.1, 3.9, 4.5, 5.1, 7.4),
age   = c(  5,   6,   7,   8,   9,  10,  11,  12))
memory <- data.frame(id    = c(1:9),
sound = c(8, 5, 6, 10, 3, 4, 7, 11, 9),
look  = c(4, 5, 3, 11, 2, 6, 4,  6, 7))
test_scores
# Linear model: y = math & x = spatial
# Linear model: y = spatial & x = math
child_vars
# Linear model: y = shoe & x = age
child_var %>%
lm(shoe ~ age,
data = .)
# Linear model: y = shoe & x = age
child_vars %>%
lm(shoe ~ age,
data = .)
# Linear model: y = shoe & x = age
child_vars %>%
lm(shoe ~ age,
data = .) %>%
sumarry()
# Linear model: y = shoe & x = age
child_vars %>%
lm(shoe ~ age,
data = .) %>%
summary()
# Linear model: y = read & x = age
lm(read ~ age,
data = .) %>%
summary()
# Linear model: y = read & x = age
child_vars %>%
lm(read ~ age,
data = .) %>%
summary()
# create new variables --> save as: child_new
child_vars %>%
dplyr::mutate(shoe_pred = 2.95 + 0.425*age) %>%
dplyr::mutate(shoe_resid = shoe - shoe_pred)
